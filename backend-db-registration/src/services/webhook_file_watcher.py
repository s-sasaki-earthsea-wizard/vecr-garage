import json
import os
import urllib.parse

from models.webhook_models import FileChangeEvent, WebhookResponse
from operations.member_registration import (
    register_human_member_from_yaml,
    register_virtual_member_from_yaml,
)
from storage.storage_client import StorageClient
from utils.logging_config import setup_logging

logger = setup_logging(__name__)


class WebhookFileWatcherService:
    """Webhooké€šçŸ¥ã«ã‚ˆã‚‹ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´ç›£è¦–ã‚µãƒ¼ãƒ“ã‚¹

    MinIOã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‹ã‚‰ã®Webhooké€šçŸ¥ã‚’å—ã‘å–ã‚Šã€ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´ã‚’æ¤œå‡ºã—ã¦
    è‡ªå‹•çš„ã«ãƒ¡ãƒ³ãƒãƒ¼ç™»éŒ²å‡¦ç†ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚

    ä¸»ãªæ©Ÿèƒ½:
    - Webhooké€šçŸ¥ã®å—ä¿¡ã¨è§£æ
    - ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´ã‚¤ãƒ™ãƒ³ãƒˆã®å‡¦ç†
    - äººé–“ãƒ¡ãƒ³ãƒãƒ¼ã¨ä»®æƒ³ãƒ¡ãƒ³ãƒãƒ¼ã®è‡ªå‹•åˆ¤åˆ¥
    - ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã¨ãƒ­ã‚°å‡ºåŠ›

    Attributes:
        storage_client (StorageClient): ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
        processed_events (Dict[str, str]): å‡¦ç†æ¸ˆã¿ã‚¤ãƒ™ãƒ³ãƒˆã®è¿½è·¡
        etag_check_enabled (bool): ETagé‡è¤‡ãƒã‚§ãƒƒã‚¯æ©Ÿèƒ½ã®æœ‰åŠ¹/ç„¡åŠ¹
    """

    def __init__(self):
        """Webhookãƒ•ã‚¡ã‚¤ãƒ«ç›£è¦–ã‚µãƒ¼ãƒ“ã‚¹ã‚’åˆæœŸåŒ–ã™ã‚‹"""
        self.storage_client = StorageClient()
        self.processed_events: dict[str, str] = {}  # event_id -> etag

        # ETagãƒã‚§ãƒƒã‚¯æ©Ÿèƒ½ã®æœ‰åŠ¹/ç„¡åŠ¹ã‚’ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—
        self.etag_check_enabled = os.getenv("WEBHOOK_ETAG_CHECK_ENABLED", "true").lower() == "true"
        logger.info(
            f"WebhookFileWatcherService initialized (ETag check: {'enabled' if self.etag_check_enabled else 'disabled'})"
        )

    def parse_webhook_payload(self, payload: dict) -> list[FileChangeEvent]:
        """Webhookãƒšã‚¤ãƒ­ãƒ¼ãƒ‰ã‚’è§£æã—ã¦ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´ã‚¤ãƒ™ãƒ³ãƒˆã‚’æŠ½å‡ºã™ã‚‹

        Args:
            payload (dict): Webhooké€šçŸ¥ã®ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰

        Returns:
            List[FileChangeEvent]: è§£æã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´ã‚¤ãƒ™ãƒ³ãƒˆã®ãƒªã‚¹ãƒˆ
        """
        events = []

        try:
            # MinIO Webhooké€šçŸ¥ã®å½¢å¼ã«å¿œã˜ã¦è§£æ
            if "Records" in payload:
                for record in payload["Records"]:
                    if "s3" in record:
                        s3_data = record["s3"]
                        bucket = s3_data["bucket"]["name"]
                        object_key = s3_data["object"]["key"]
                        event_name = record.get("eventName", "")

                        # ETagã¨ã‚µã‚¤ã‚ºã‚’å–å¾—
                        etag = s3_data["object"].get("eTag", "").strip('"')
                        size = s3_data["object"].get("size", 0)
                        event_time = record.get("eventTime", "")

                        event = FileChangeEvent(
                            event_name=event_name,
                            bucket_name=bucket,
                            object_name=object_key,
                            etag=etag,
                            size=size,
                            event_time=event_time,
                        )
                        events.append(event)
                        logger.info(f"Parsed event: {event_name} for {object_key}")

            # ã‚«ã‚¹ã‚¿ãƒ Webhookå½¢å¼ã®ã‚µãƒãƒ¼ãƒˆ
            elif "events" in payload:
                for event_data in payload["events"]:
                    event = FileChangeEvent(**event_data)
                    events.append(event)
                    logger.info(f"Parsed custom event for {event.object_name}")

            # å˜ä¸€ã‚¤ãƒ™ãƒ³ãƒˆå½¢å¼ã®ã‚µãƒãƒ¼ãƒˆ
            elif "event_name" in payload:
                event = FileChangeEvent(**payload)
                events.append(event)
                logger.info(f"Parsed single event for {event.object_name}")

        except Exception as e:
            logger.error(f"Failed to parse webhook payload: {e}")
            logger.debug(f"Payload: {json.dumps(payload, indent=2)}")

        return events

    def should_process_event(self, event: FileChangeEvent) -> bool:
        """ã‚¤ãƒ™ãƒ³ãƒˆã‚’å‡¦ç†ã™ã¹ãã‹ã©ã†ã‹ã‚’åˆ¤å®šã™ã‚‹

        Args:
            event (FileChangeEvent): å‡¦ç†å¯¾è±¡ã®ã‚¤ãƒ™ãƒ³ãƒˆ

        Returns:
            bool: å‡¦ç†ã™ã¹ãå ´åˆã¯True
        """
        # ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚­ãƒ¼ã‚’URLãƒ‡ã‚³ãƒ¼ãƒ‰
        try:
            decoded_object_name = urllib.parse.unquote(event.object_name)
            # ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ã§ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰å‰å¾Œã®ãƒ‘ã‚¹ã‚’è¨˜éŒ²
            if decoded_object_name != event.object_name:
                logger.debug(
                    f"URL decoded object name: {event.object_name} -> {decoded_object_name}"
                )
        except Exception as e:
            logger.warning(f"Failed to URL decode object name '{event.object_name}': {e}")
            # ãƒ‡ã‚³ãƒ¼ãƒ‰ã«å¤±æ•—ã—ãŸå ´åˆã¯å…ƒã®ãƒ‘ã‚¹ã‚’ä½¿ç”¨
            decoded_object_name = event.object_name

        # ã‚¤ãƒ™ãƒ³ãƒˆIDã‚’ç”Ÿæˆï¼ˆãƒ‡ã‚³ãƒ¼ãƒ‰å¾Œã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆå + ETagï¼‰
        event_id = f"{decoded_object_name}_{event.etag}"

        # ETagãƒã‚§ãƒƒã‚¯ãŒæœ‰åŠ¹ãªå ´åˆã®ã¿é‡è¤‡ãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œ
        if self.etag_check_enabled:
            if event_id in self.processed_events:
                logger.debug(f"Skipping already processed event: {event_id}")
                return False
        else:
            logger.debug(f"ETag check disabled - processing event: {event_id}")

        # å¯¾è±¡å¤–ã®ã‚¤ãƒ™ãƒ³ãƒˆã‚’ã‚¹ã‚­ãƒƒãƒ—
        if event.event_name not in [
            "s3:ObjectCreated:Put",
            "s3:ObjectCreated:Post",
            "s3:ObjectCreated:CompleteMultipartUpload",
            "s3:ObjectCreated:Copy",
        ]:
            logger.debug(f"Skipping non-creation event: {event.event_name}")
            return False

        # YAMLãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ã‚’å‡¦ç†ï¼ˆãƒ‡ã‚³ãƒ¼ãƒ‰å¾Œã®ãƒ‘ã‚¹ã§åˆ¤å®šï¼‰
        if not decoded_object_name.endswith((".yaml", ".yml")):
            logger.debug(f"Skipping non-YAML file: {decoded_object_name}")
            return False

        # å¯¾è±¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ã‚’å‡¦ç†ï¼ˆãƒ‡ã‚³ãƒ¼ãƒ‰å¾Œã®ãƒ‘ã‚¹ã§åˆ¤å®šï¼‰
        # æ–°ã—ã„ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã«å¯¾å¿œ: samples/ã¨test_cases/ä¸¡æ–¹ã‚’ã‚µãƒãƒ¼ãƒˆ
        target_patterns = [
            "data/samples/human_members/",
            "data/samples/virtual_members/",
            "data/test_cases/human_members/",
            "data/test_cases/virtual_members/",
            # æ—§å½¢å¼ã¨ã®äº’æ›æ€§ã®ãŸã‚ï¼ˆæ®µéšçš„ç§»è¡Œï¼‰
            "data/human_members/",
            "data/virtual_members/",
        ]

        if not any(decoded_object_name.startswith(pattern) for pattern in target_patterns):
            logger.debug(f"Skipping file outside target directories: {decoded_object_name}")
            return False

        return True

    def process_file_event(self, event: FileChangeEvent) -> bool:
        """ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´ã‚¤ãƒ™ãƒ³ãƒˆã‚’å‡¦ç†ã™ã‚‹

        Args:
            event (FileChangeEvent): å‡¦ç†ã™ã‚‹ã‚¤ãƒ™ãƒ³ãƒˆ

        Returns:
            bool: å‡¦ç†ãŒæˆåŠŸã—ãŸå ´åˆã¯True

        Raises:
            ValidationError: YAMLãƒ‡ãƒ¼ã‚¿ã®ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã«å¤±æ•—ã—ãŸå ´åˆ
            DatabaseError: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ“ä½œã«å¤±æ•—ã—ãŸå ´åˆ
            Exception: ãã®ä»–ã®äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆ
        """
        # ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚­ãƒ¼ã‚’URLãƒ‡ã‚³ãƒ¼ãƒ‰
        try:
            decoded_object_name = urllib.parse.unquote(event.object_name)
            # ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°ã§ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰å‰å¾Œã®ãƒ‘ã‚¹ã‚’è¨˜éŒ²
            if decoded_object_name != event.object_name:
                logger.debug(
                    f"URL decoded object name: {event.object_name} -> {decoded_object_name}"
                )
        except Exception as e:
            logger.warning(f"Failed to URL decode object name '{event.object_name}': {e}")
            # ãƒ‡ã‚³ãƒ¼ãƒ‰ã«å¤±æ•—ã—ãŸå ´åˆã¯å…ƒã®ãƒ‘ã‚¹ã‚’ä½¿ç”¨
            decoded_object_name = event.object_name

        logger.info(f"Processing file event: {event.event_name} for {decoded_object_name}")

        # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã«åŸºã¥ã„ã¦ãƒ¡ãƒ³ãƒãƒ¼ã‚¿ã‚¤ãƒ—ã‚’åˆ¤å®šï¼ˆãƒ‡ã‚³ãƒ¼ãƒ‰å¾Œã®ãƒ‘ã‚¹ã§åˆ¤å®šï¼‰
        if "human_members" in decoded_object_name:
            register_human_member_from_yaml(decoded_object_name)
            logger.info(f"âœ… Successfully registered human member from: {decoded_object_name}")

        elif "virtual_members" in decoded_object_name:
            register_virtual_member_from_yaml(decoded_object_name)
            logger.info(f"âœ… Successfully registered virtual member from: {decoded_object_name}")

        else:
            logger.warning(f"âš ï¸  Unknown file type, skipping: {decoded_object_name}")
            return False

        # ETagãƒã‚§ãƒƒã‚¯ãŒæœ‰åŠ¹ãªå ´åˆã®ã¿å‡¦ç†æ¸ˆã¿ã‚¤ãƒ™ãƒ³ãƒˆã¨ã—ã¦ãƒãƒ¼ã‚¯
        if self.etag_check_enabled:
            # å‡¦ç†æ¸ˆã¿ã‚¤ãƒ™ãƒ³ãƒˆã¨ã—ã¦ãƒãƒ¼ã‚¯ï¼ˆãƒ‡ã‚³ãƒ¼ãƒ‰å¾Œã®ãƒ‘ã‚¹ã§ã‚¤ãƒ™ãƒ³ãƒˆIDç”Ÿæˆï¼‰
            # TODO: å°†æ¥çš„ã«file_uriãƒ™ãƒ¼ã‚¹ã®UPSERTå®Ÿè£…ã§ã“ã®ETagãƒã‚§ãƒƒã‚¯ã¯ä¸è¦ã«ãªã‚‹
            # Issue: https://github.com/your-org/vecr-garage/issues/xxx
            # ç¾åœ¨ã¯DBå´ã®ä¸€æ™‚çš„ãªUPSERTå‡¦ç†ã«ã‚ˆã‚ŠåŒã˜ãƒ•ã‚¡ã‚¤ãƒ«ã®æ›´æ–°ãŒæ­£ã—ãå‡¦ç†ã•ã‚Œã‚‹
            event_id = f"{decoded_object_name}_{event.etag}"
            self.processed_events[event_id] = event.etag
            logger.debug(f"Marked event as processed: {event_id}")
        else:
            logger.debug(
                f"ETag check disabled - not marking event as processed: {decoded_object_name}"
            )

        return True

    def handle_webhook(self, payload: dict) -> WebhookResponse:
        """Webhooké€šçŸ¥ã‚’å‡¦ç†ã™ã‚‹

        Args:
            payload (dict): Webhooké€šçŸ¥ã®ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰

        Returns:
            WebhookResponse: å‡¦ç†çµæœ
        """
        logger.info("ğŸ“¥ Received webhook notification")

        processed_files = []
        errors = []

        try:
            # ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰ã‚’è§£æ
            events = self.parse_webhook_payload(payload)

            if not events:
                logger.warning("No valid events found in webhook payload")
                return WebhookResponse(
                    success=False,
                    message="No valid events found in webhook payload",
                    errors=["No valid events found"],
                )

            logger.info(f"Found {len(events)} events to process")

            # å„ã‚¤ãƒ™ãƒ³ãƒˆã‚’å‡¦ç†
            for event in events:
                if self.should_process_event(event):
                    try:
                        if self.process_file_event(event):
                            processed_files.append(event.object_name)
                        else:
                            errors.append(f"Failed to process {event.object_name}")
                    except Exception as e:
                        # ValidationError, DatabaseError, ãã®ä»–å…¨ã¦ã®ä¾‹å¤–ã‚’ã“ã“ã§ã‚­ãƒ£ãƒƒãƒ
                        # ã‚¨ãƒ©ãƒ¼ã¯æ—¢ã«register_*_member_from_yamlé–¢æ•°å†…ã§ãƒ­ã‚°å‡ºåŠ›æ¸ˆã¿
                        errors.append(f"Failed to process {event.object_name}: {str(e)}")
                        logger.error(
                            f"âŒ Failed to process file event {event.object_name}: {str(e)}"
                        )
                else:
                    logger.debug(f"Skipped duplicate event for {event.object_name}")

            # ETagãƒã‚§ãƒƒã‚¯ãŒæœ‰åŠ¹ãªå ´åˆã®ã¿ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚’å®Ÿè¡Œ
            if self.etag_check_enabled:
                # å‡¦ç†æ¸ˆã¿ã‚¤ãƒ™ãƒ³ãƒˆã®å±¥æ­´ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ï¼ˆå¤ã„ã‚¨ãƒ³ãƒˆãƒªã‚’å‰Šé™¤ï¼‰
                self._cleanup_processed_events()

            # æˆåŠŸã®åˆ¤å®š: ã‚¨ãƒ©ãƒ¼ãŒ0ã®å ´åˆï¼ˆé‡è¤‡æ¤œå‡ºã«ã‚ˆã‚‹å‡¦ç†ã‚¹ã‚­ãƒƒãƒ—ã¯æ­£å¸¸ãªå‹•ä½œï¼‰
            success = len(errors) == 0

            # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®æ§‹ç¯‰
            if len(processed_files) > 0:
                message = f"Processed {len(processed_files)} files successfully"
            else:
                message = "No new files to process (duplicate detection working)"

            if errors:
                message += f", {len(errors)} errors occurred"

            return WebhookResponse(
                success=success,
                message=message,
                processed_files=processed_files,
                errors=errors,
            )

        except Exception as e:
            logger.error(f"ğŸ’¥ Error handling webhook: {e}")
            return WebhookResponse(
                success=False,
                message=f"Error handling webhook: {str(e)}",
                errors=[str(e)],
            )

    def _cleanup_processed_events(self, max_events: int = 1000):
        """å‡¦ç†æ¸ˆã¿ã‚¤ãƒ™ãƒ³ãƒˆã®å±¥æ­´ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã™ã‚‹

        Args:
            max_events (int): ä¿æŒã™ã‚‹æœ€å¤§ã‚¤ãƒ™ãƒ³ãƒˆæ•°
        """
        if len(self.processed_events) > max_events:
            # å¤ã„ã‚¨ãƒ³ãƒˆãƒªã‚’å‰Šé™¤ï¼ˆç°¡æ˜“çš„ãªå®Ÿè£…ï¼‰
            items_to_remove = len(self.processed_events) - max_events
            keys_to_remove = list(self.processed_events.keys())[:items_to_remove]

            for key in keys_to_remove:
                del self.processed_events[key]

            logger.debug(f"Cleaned up {items_to_remove} old processed events")

    def get_status(self) -> dict:
        """ã‚µãƒ¼ãƒ“ã‚¹ã®çŠ¶æ…‹ã‚’å–å¾—ã™ã‚‹

        Returns:
            dict: ã‚µãƒ¼ãƒ“ã‚¹çŠ¶æ…‹ã®æƒ…å ±
        """
        return {
            "service_type": "webhook",
            "processed_events_count": len(self.processed_events),
            "storage_client_available": self.storage_client is not None,
        }
